{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .values return a Numpy representation of the df.\n",
    "X=iris.data[['petal length (cm)','petal width (cm)']].values\n",
    "Y=iris[\"target\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding bias to each instances\n",
    "X_w_bias=np.c_[np.ones(len(X)),X]\n",
    "len(X_w_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Ratio: 0.2\n",
    "# Validation Ratio: 0.2\n",
    "# Need to convert to int else cannot slice\n",
    "np.random.seed(42)\n",
    "total_size=len(X_w_bias)\n",
    "test_size=int(total_size*0.2)\n",
    "validation_size=int(total_size*0.2)\n",
    "train_size=int(total_size-(validation_size+test_size))\n",
    "\n",
    "random_index=np.random.permutation(total_size)\n",
    "\n",
    "X_train = X_w_bias[random_index[:train_size]]\n",
    "Y_train=Y[random_index[:train_size]]\n",
    "\n",
    "X_valid=X_w_bias[random_index[train_size:-test_size]]\n",
    "Y_valid=Y[random_index[train_size:-test_size]]\n",
    "\n",
    "X_test=X_w_bias[random_index[-test_size:]]\n",
    "Y_test=Y[random_index[-test_size:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy way of ohe\n",
    "# if a is a NumPy array, then a[[1, 3, 2]] \n",
    "# returns an array with 3 rows equal to a[1], a[3] and a[2] \n",
    "def to_one_hot(Y):\n",
    "    return np.diag(np.ones(Y.max() + 1))[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_ohe=to_one_hot(Y_train)\n",
    "Y_valid_ohe=to_one_hot(Y_valid)\n",
    "Y_test_ohe=to_one_hot(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling data Excluding Bias\n",
    "s=X_train[:,1:].std(axis=0)\n",
    "m=X_train[:,1:].mean(axis=0)\n",
    "\n",
    "X_train[:,1:]=(X_train[:,1:]-m)/s\n",
    "X_test[:,1:]=(X_test[:,1:]-m)/s\n",
    "X_valid[:,1:]=(X_valid[:,1:]-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]  # == 3 (2 features plus the bias term)\n",
    "n_outputs = len(np.unique(Y))  # == 3 (there are 3 iris classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax function\n",
    "def softmax(logits):\n",
    "    exps = np.exp(logits)\n",
    "    exp_sums = exps.sum(axis=1, keepdims=True)\n",
    "    return exps / exp_sums\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(Y_true, Y_proba, epsilon=1e-5):\n",
    "    #epsilon is a small constant added to avoid log(0), set to 1e-5.\n",
    "    m = Y_true.shape[0]\n",
    "\n",
    "    xentropy_losses = -(Y_true * np.log(Y_proba + epsilon))\n",
    "    return xentropy_losses.sum()/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3)\n",
      "(30, 3)\n"
     ]
    }
   ],
   "source": [
    "#debugging\n",
    "print(Y_valid_ohe.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 0, xentropy_losses: 3.7085808486476917\n",
      "current epoch: 1000, xentropy_losses: 0.1495820404906828\n",
      "current epoch: 2000, xentropy_losses: 0.13540154847307986\n",
      "current epoch: 3000, xentropy_losses: 0.12563653832371222\n",
      "current epoch: 4000, xentropy_losses: 0.11856991608848257\n",
      "current epoch: 5000, xentropy_losses: 0.11373607223021413\n",
      "current epoch: 6000, xentropy_losses: 0.11060518361142271\n",
      "current epoch: 7000, xentropy_losses: 0.1086800041113589\n",
      "current epoch: 8000, xentropy_losses: 0.10757166633306339\n",
      "current epoch: 9000, xentropy_losses: 0.10700450245408859\n",
      "current epoch: 10000, xentropy_losses: 0.10679240635369075\n",
      "current epoch: 11000, xentropy_losses: 0.10681236180759407\n",
      "current epoch: 12000, xentropy_losses: 0.10698352035063056\n",
      "current epoch: 13000, xentropy_losses: 0.10725261265613953\n",
      "current epoch: 14000, xentropy_losses: 0.10758430809572092\n",
      "current epoch: 15000, xentropy_losses: 0.10795498173090191\n",
      "current epoch: 16000, xentropy_losses: 0.10834870723473895\n",
      "Early Stopping NOW!\n",
      "Final validation loss: 0.10834870723473895\n"
     ]
    }
   ],
   "source": [
    "eta = 0.4 # learning rate\n",
    "n_epochs = 30000\n",
    "\n",
    "epsilon = 1e-5\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "patience_counter=0\n",
    "\n",
    "max_patience=5\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "#initializes the weights (Theta) randomly\n",
    "Theta = np.random.randn(n_inputs, n_outputs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    #softmax score formula\n",
    "    #training X_train\n",
    "    logits = X_train @ Theta\n",
    "    \n",
    "    Y_proba = softmax(logits)\n",
    "\n",
    "    #compute loss for every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        #cross entropy on validation set\n",
    "        Y_proba_valid = softmax(X_valid @ Theta)\n",
    "        xentropy_losses = cross_entropy_loss(Y_valid_ohe,Y_proba_valid)\n",
    "        print(f'current epoch: {epoch}, xentropy_losses: {xentropy_losses}')\n",
    "\n",
    "        if xentropy_losses<best_loss:\n",
    "            best_loss=xentropy_losses\n",
    "            patience_counter=0\n",
    "        else:\n",
    "            patience_counter+=1\n",
    "\n",
    "        if patience_counter>max_patience:\n",
    "            print('Early Stopping NOW!')\n",
    "            break\n",
    "\n",
    "\n",
    "    error = Y_proba - Y_train_ohe\n",
    "    \n",
    "    \n",
    "    gradients = 1 / len(X_train) * X_train.T @ error\n",
    "    \n",
    "    Theta = Theta - eta * gradients\n",
    "\n",
    "Y_proba_valid = softmax(X_valid @ Theta)\n",
    "final_loss = cross_entropy_loss(Y_valid_ohe, Y_proba_valid)\n",
    "print(f'Final validation loss: {final_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83952886,  7.64029406, -7.47368453],\n",
       "       [-8.20116368, -2.31041246, 11.56631566],\n",
       "       [-6.5302452 ,  0.93794597,  7.46947239]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current weights\n",
    "Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score for validation set: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "logits=X_valid @ Theta\n",
    "predicted_proba=softmax(logits)\n",
    "predicted_labels=np.argmax(predicted_proba,axis=1)\n",
    "acc_score=(predicted_labels==Y_valid).mean()\n",
    "print(f'accuracy score for validation set: {acc_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score for test set: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "logits=X_test@Theta\n",
    "predicted_proba=softmax(logits)\n",
    "predicted_labels=np.argmax(predicted_proba,axis=1)\n",
    "acc_score=(predicted_labels==Y_test).mean()\n",
    "print(f'accuracy score for test set: {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
